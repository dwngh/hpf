{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e226c7a9-dd06-4233-8c2b-e9c3cd48471e",
   "metadata": {},
   "source": [
    "# Tóm tắt học máy thống kê tới giữa kỳ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb8cf58-2e13-4611-842d-1b94cb7bbefb",
   "metadata": {},
   "source": [
    "## Lecture 1:\n",
    "**Định nghĩa Học máy:** Thuật toán $A$ được coi là học từ kinh nghiệm $E$ đối với lớp bài toán $T$ và độ đo hiệu năng $P$ nếu hiệu năng đo bằng $P$ của $A$ đối với nhiệm vụ $T$ tăng với kinh nghiệm $E$.\n",
    "\n",
    "Học có giám sát, Học không giám sát, Học tăng cường\n",
    "\n",
    "Một vòng đời phát triển và triển khai mô hình học máy:\n",
    "1. Thu thập và chuẩn bị\n",
    "2. Trích chọn đặc trưng dữ liệu\n",
    "3. Huấn luyện mô hình\n",
    "4. Đánh giá mô hình\n",
    "5. Triển khai mô hình\n",
    "6. Sử dụng mô hình\n",
    "7. Giám sát mô hình\n",
    "8. Bảo trì mô hình\n",
    "\n",
    "### Ôn lại Xác suất:\n",
    "\n",
    "* **Sample space**: $\\Omega$ is the set of all possible outcomes or results (of a random experiment)\n",
    "* **Event space**: The set $\\mathcal{F} \\subset 2^{\\Omega}$ is a $\\sigma$-algebra of the sets of $\\Omega$. Each element in $\\mathcal{F}$ is an **event** (subset of $\\Omega$).\n",
    "* **Probability measure**: a function $\\mathbb{P}: \\mathcal{F} \\rightarrow \\mathbb{R}^+$ satisfies the following properties:\n",
    "    * $\\mathbb{P}(\\Omega) = 1, \\mathbb{P}(\\emptyset) = 0$;\n",
    "    * $A_i \\in \\mathcal{F}, A_i \\cap A_j = \\emptyset, \\forall i \\neq j$ then $\\mathbb{P}(\\bigcup_{i=1}^\\infty A_i) = \\sum_{i=1}^\\infty \\mathbb{P}(A_i)$ ;\n",
    " \n",
    "* **Bayes' Theorem**:\n",
    "$$P(B|A) = \\frac{P(A|B) \\cdot P(B)}{P(A)}$$\n",
    "where: $P(A|B)$ is posterior, $P(A|B)$ is the likelihood, $P(B)$ is marginal or prior probability\n",
    "\n",
    "* Random variable, Probability Distribution (CDF, PDF\n",
    "* **Maximum Likelihood Estimation** (MLE): Given $L(\\theta)$ is the likelihood of $\\theta$ w.r.t. the dataset $D$. MLE is finding $\\theta$ that maximizes $L(\\theta)$\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2336f86-4dc7-4101-9116-bff0ecbb27f0",
   "metadata": {},
   "source": [
    "## Lecture 2:\n",
    "\n",
    "### Lý thuyết về phân lớp\n",
    "**Bài toán phân lớp thống kê:** Cho tập đầu vào $X$ và tập các phân lớp của $X$ là $Y=\\{1, 2, ..., C\\}$. Tập dữ liệu huấn luyện $D=\\{(x_i, y_i)\\}$ với $(x_i, y_i) \\in X \\times Y$ được lấy mẫu theo phân bố dữ liệu $\\mathcal{P}(x, y)$, hãy tìm một mô hình phân lớp $h:X \\rightarrow Y$ phân lớp tốt trên phân bố $P$.\n",
    "\n",
    "Phân lớp tốt = xác suất $P_{(x, y) \\sim P}\\{h(x) \\neq y\\}$ nhỏ với sự kiện phân lớp sai $\\{h(x) \\neq y\\}$ là một sự kiện ngẫu nhiên trong phân bố $P$.\n",
    "\n",
    "Xác suất lỗi thực nghiệm:\n",
    "\n",
    "$$\\hat{\\text{err}}_D(h) = \\frac{1}{n}\\sum_{i=1}^n \\mathbb{I}[h(x) \\neq y]$$\n",
    "\n",
    "**Định lý Xấp xỉ rủi ro kỳ vọng bằng rủi ro thực nghiệm**: Xét một hàm phân lớp $h$ cố định, nếu các mẫu dữ liệu $(x, y)$ được lấy mẫu độc lập từ phân bố $\\mathcal{P}$ thì với mọi giá trị $\\epsilon > 0$:\n",
    "\n",
    "$$P_{D \\sim \\mathcal{P}^n}[|\\hat{\\text{err}}_D(h) - \\hat{\\text{err}}_\\mathcal{P}(h)| < \\epsilon] \\geq 1 - 2e^{-2n\\epsilon^2} $$\n",
    "\n",
    "**Định nghĩa hàm phân lớp tối ưu Bayes**: Hàm phân lớp tối ưu Bayes là hàm phân lớp thoả mãn đẳng thức:\n",
    "\n",
    "$$h^*(x) = \\text{argmax}_y P(y|x),$$\n",
    "\n",
    "trong đó, $P(y|x)$ được gọi là phân bố hậu nghiệm (posterior distribution) của nhãn $y$ khi biết đầu vào $x$ trong phân bố $\\mathcal{P}$.\n",
    "\n",
    "Sử dụng ma thuật, ta có được $$\\text{err}_\\mathcal{P}(h) = \\mathbb{P}_\\mathcal{P}[h(x) \\neq y] = \\int_{x} [\\sum_y \\mathbb{I}[h(x) \\neq y] P(y|x) ] P(x)dx$$\n",
    "\n",
    "Đại lượng $\\text{err}_\\mathcal{P}(h, x)$ là xác suất xảy ra lỗi khi áp dụng phân lớp $h$ trên dữ liệu $x$. Ta có thể ước lượng $\\text{err}_\\mathcal{P}(h, x)$ như sau:\n",
    "\n",
    "$$\\text{err}_\\mathcal{P}(h, x) = \\sum_{y \\neq h(x)} P(y|x) =  1 - P(h(x)|x).$$\n",
    "\n",
    "Tới đây có 2 cách tiếp cận chính dựa trên học máy:\n",
    "* **Mô hình sinh**: Là mô hình học máy ước lượng trực tiếp mật độ xác suất $p(x, y)$ từ phân bố $\\mathcal{P}$. Từ phân bố này, ta có thể tìm $h^*$ theo khai triển sau:\n",
    "$$h^*(x) = \\text{argmax}_y p(x, y)$$\n",
    "* **Mô hình phân biệt**: Là mô hình học máy ước lượng xác suất $P(y|x)$ hoặc trực tiếp hàm phân lớp $h^*(x)$.\n",
    "\n",
    "### Logistic Regression\n",
    "\n",
    "Description:\n",
    "* **Data**: $D=\\{(x_1, y_1), (x_2, y_2),...,(x_n, y_n)\\}$\n",
    "* **Model**: $f(x) = w^Tx + w_0; Y|X = x \\sim \\text{Ber}(y|\\sigma(f(x)))$\n",
    "* **Parameter**: $\\theta = (w, w_0)$\n",
    "\n",
    "Ý tưởng: Biến đổi không gian tuyến tính rồi sử dụng hàm Sigmoid để biến khoảng cách thành xác suất.\n",
    "\n",
    "Quá trình training: Sử dụng nguyên lý MLE với\n",
    "$$L(\\theta) = P(D|\\theta) = \\prod_{i=1}^n P(y_i | x_i) = \\prod_{i=1}^n \\mu_i^{y_i} (1 - \\mu_i)^{1-y_i}.$$\n",
    "\n",
    "Trong đó $P(y_i | x_i) =  \\mu_i^{y_i} (1 - \\mu_i)^{1-y_i}$ vì đang giả sử phân bố Bernoulli với mô hình. Và tham số $\\mu_i$ chính là đầu ra mô hình.\n",
    "\n",
    "Thay vì tối ưu bằng likelihood, người ta sử dụng NLL để tối ưu:\n",
    "$$\\mathcal{l}(\\theta) = - \\log L(\\theta) = \\sum_{i=1}^n -y_i \\log \\mu_i - (1-y_i) \\log (1-\\mu_i).$$\n",
    "\n",
    "Sử dụng Gradient Descent để tối ưu mô hình, cập nhật tham số:\n",
    "$$\\theta \\leftarrow \\theta - \\alpha \\nabla_\\theta \\mathcal{l}(\\theta)$$\n",
    "\n",
    "Nếu bị bắt giải tay:\n",
    "$$\\nabla_w \\mathcal{l}(w, w_0) = \\sum_{i=1}^n \\frac{\\partial \\mathcal{l}}{\\partial \\mu_i} \\frac{\\partial \\mu_i}{\\partial w} = \\sum_{i=1}^n (\\mu_i - y_i)x_i$$\n",
    "$$\\nabla_w \\mathcal{l}(w, w_0) = \\sum_{i=1}^n \\frac{\\partial \\mathcal{l}}{\\partial \\mu_i} \\frac{\\partial \\mu_i}{\\partial w_0} = \\sum_{i=1}^n (\\mu_i - y_i)$$\n",
    "\n",
    "### k Nearest Neighbor\n",
    "ý tưởng: Với bộ dữ liệu $D=\\{(x_i, y_i)| i = 1...n\\}$, ta tiến hành phân lớp một điểm $x$ như sau:\n",
    "* Tính khoảng cách $d(x, x_i), i=1,2,...,n$\n",
    "* Lấy $k$ điểm gần nhất $(x_j, y_j)^k_{j=1}$\n",
    "* Trả về nhãn với số lượng nhiều nhất"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b84751c3-99ee-4a47-b289-a2444299cd95",
   "metadata": {},
   "source": [
    "## Lecture 3: Support Vector Machine\n",
    "\n",
    "* Khái niệm Perceptron: Một hyperplane dựa trên trọng số $w$ và bias $b$ để chia không gian: $(H): \\{x: w^T x + b = 0\\}$\n",
    "    * Positive class:  $(H): \\{x: w^T x + b \\geq 0\\}$\n",
    "    * Negative class:  $(H): \\{x: w^T x + b < 0\\}$\n",
    "* Khái niệm Linear Separable, Non-linear Separable\n",
    "* Khái niệm về Margin (khoảng cách từ điểm gần nhất cho đến hyperplane):\n",
    "$$\\delta = \\min_{i=1}^n \\frac{|w^Tx_i + b|}{||w||} $$\n",
    "* Huấn luyện Perceptron: Tìm $w$ và $b$ thoả mãn $s_i = y_i (w^T x_i + b) \\geq 0$\n",
    "    * Khởi tạo tham số bằng $0$ hết\n",
    "    * Lặp với từng mẫu, nếu $s_i \\geq 0$ thì skip, không thì update theo gradient descent\n",
    "    * Dừng khi tất cả $s_i \\geq 0$\n",
    "## Hard margin SVM\n",
    "\n",
    "Hyperplane bây giờ không chỉ bắt buộc chia đôi không gian mà phải thoả mãn lề tối thiểu $\\delta$. Tối ưu = maximize lề tối thiểu. Nhưng vì một lí do thần kỳ nào đó, người ta chứng minh được luôn có thể giãn để những điểm nằm trên margin thoả mãn $y_i(w^Tx + b) = 1$ vì vậy mà $\\delta = \\frac{1}{||w||}$ và bài toán trở thành minimize $$\\min_{w, b}\\frac{1}{2}||w||^2$$\n",
    "$$\\text{s.t. }y_i(w^Tx + b) \\geq 1, \\forall i$$. \n",
    "\n",
    "## Soft margin SVM\n",
    "\n",
    "Tuy nhiên, không phải lúc nào data cũng linear separable nên người ta đẻ ra thêm Soft margin SVM\n",
    "$$\\min_{w, b} \\frac{1}{2}||w||^2 + C\\sum_{i=1}^n \\max(0, 1 - y_i(w^Tx + b))$$\n",
    "\n",
    "Thuật toán update:\n",
    "* Khởi tạo cả lũ $=0$\n",
    "* Lặp tới chết:\n",
    "    * Tính điểm $s_i = y_i (w^Tx_i + b)$\n",
    "    * Nếu $s_i \\geq 1$, skip\n",
    "    * Nếu không, cập nhật $w, b$:\n",
    "        * $w \\leftarrow (1 - \\lambda)w + \\lambda y_ix_i$\n",
    "        * $b \\leftarrow b + \\lambda y_i$  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5aa86ce-cfef-40cf-86d2-c5c7e39aeba4",
   "metadata": {},
   "source": [
    "## Lecture 4: Cây quyết định\n",
    "* Cây quyết định hoạt động như thế nào?\n",
    "* Thuật toán Hunt để xây dựng cây: (đệ quy)\n",
    "    * $D_t$ là dữ liệu tới node hiện tại\n",
    "    * Thực hiện thao tác sau:\n",
    "        * Nếu $D_t$ cùng thuộc một lớp thì đây sẽ là node lá\n",
    "        * Nếu không thì sử dụng \"attribute test\" để chia các nhóm tiếp và đệ quy (tới cùng mà chưa chia được hết thì gặp vấn đề Identical attribute values)\n",
    "* Attribute test:\n",
    "    * Binary: Chia bình thường\n",
    "    * Nominal: Chia nhị phân hoặc chia theo nhiều giá trị (multiway)\n",
    "    * Ordinal: Chia như Nominal nhưng với chia nhị phân thì phải giữ nguyên thứ tự\n",
    "    * Continuous: Rời rạc hoá (Discretization) hoặc Binary Decision (chọn một giá trị để chia nhị phân)\n",
    "\n",
    "* Chia thế nào cho ổn: Sử dụng cách tiếp cận tham lam, tại mỗi bước, chọn phép chia từ node cha làm sao để các node con tinh khiết hơn node cha. Hay nói cách khác ta đo độ impurity của node cha và node con để chọn cách chia\n",
    "    * Impurity của node cha $P$\n",
    "    * Impurity của các node con qua từng phép chia bằng TB có trọng số: $M = \\sum_i \\frac{n_i}{n} \\text{Impurity}_i$\n",
    "    * Tính gain ($P-M$) và chọn ra phép chia nào có gain to nhất là best split.\n",
    "* Các cách tính Impurity:\n",
    "    * Gini Index: $\\text{Gini}(t) = 1 - \\sum_{c=1}^C p_c(t)^2$;\n",
    "    * Entropy: $H(t) = - \\sum_{c=1}^C p_c(t) \\log p_c(t)$;\n",
    "    * Classification Error: $CE(t) = 1 - \\max[p_c(t)]$;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce4cd74-cfd7-4572-af3b-25bedb9e8eea",
   "metadata": {},
   "source": [
    "## Lecture 5: MLP \n",
    "### Perceptron\n",
    "### MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2abdb4-9255-42f9-901e-1f46c8dabcc5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
